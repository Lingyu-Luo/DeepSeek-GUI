import streamlit as st
from openai import OpenAI
import os
import json
import re
from datetime import datetime
import base64
from search_api import search_results

# é…ç½®åŸºç¡€ä¿¡æ¯
client = OpenAI(
    base_url='https://api.siliconflow.cn/v1/',
    api_key=os.getenv("SILICONFLOW_API_KEY")
)

HISTORY_DIR = "ChatHistory"
os.makedirs(HISTORY_DIR, exist_ok=True)
#name_model = "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
name_model = "deepseek-ai/DeepSeek-V3"
#vlm_model = "deepseek-ai/deepseek-vl2"
vlm_model = "Qwen/Qwen2.5-VL-72B-Instruct"
vlm_max_tokens = 4096

def init_session():
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'current_convo' not in st.session_state:
        st.session_state.current_convo = None
    if 'convo_list' not in st.session_state:
        st.session_state.convo_list = []
    # æ–°å¢æ¨¡å‹å‚æ•°åˆå§‹åŒ–
    if 'selected_model' not in st.session_state:
        st.session_state.selected_model = "deepseek-ai/DeepSeek-R1"
    if 'max_tokens' not in st.session_state:
        st.session_state.max_tokens = 2048
    if 'temperature' not in st.session_state:
        st.session_state.temperature = 1.0
    if 'top_p' not in st.session_state:
        st.session_state.top_p = 1.0

    # å†å²è®°å½•å…¼å®¹ï¼ˆå¤„ç†å¤šæ¨¡æ€æ¶ˆæ¯ï¼‰
    for msg in st.session_state.get('messages', []):
        if isinstance(msg.get("content"), list):
            for item in msg["content"]:
                if item["type"] == "image_url":
                    item["image_url"]["url"] = str(item["image_url"]["url"])


def generate_filename(content):
    # æå–æ–‡æœ¬å†…å®¹ç”¨äºç”Ÿæˆæ–‡ä»¶å
    text_content = ""
    if isinstance(content, list):
        texts = [item["text"] for item in content if isinstance(item, dict) and item.get("type") == "text"]
        text_content = " ".join(texts)
    else:
        text_content = str(content)

    response = client.chat.completions.create(
        model=name_model,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå¯¹è¯å‘½ååŠ©æ‰‹ï¼Œå¸®åŠ©æå–å¯¹è¯å…³é”®è¯ä½œä¸ºå¯¹è¯è®°å½•æ–‡ä»¶åï¼Œåäº”å­—ä»¥å†…ã€‚"},
            {"role": "user", "content": "æå–å¯¹è¯çš„ä¸»é¢˜ï¼ˆä»…è¾“å‡ºä¸»é¢˜æœ¬èº«ï¼‰ï¼š" + text_content}],
        temperature=1.5,
        max_tokens=1024
    )
    clean_content = response.choices[0].message.content.strip()

    clean_content = re.sub(r'[\n\r\t\\/*?:"<>|]', "", clean_content)[:15]
    timestamp = datetime.now().strftime("%m%d%H%M")
    return f"{timestamp}_{clean_content}.json" if clean_content else f"{timestamp}_æœªå‘½å.json"

def generate_search_keyword(query):
    response = client.chat.completions.create(
        model=name_model,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœç´¢å…³é”®è¯ä¼˜åŒ–åŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·é—®é¢˜ç”Ÿæˆ3ä¸ªæœ€ç›¸å…³çš„æœç´¢å…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”ã€‚"},
            {"role": "user", "content": query}],
        temperature=0.6,
        max_tokens=1024
    )

    keywords = response.choices[0].message.content.strip()
    # return re.sub(r"[^a-zA-Z0-9\u4e00-\u9fa5,]", "", keywords)
    return keywords

def convert_messages_for_api(messages, use_vlm):
    """è½¬æ¢æ¶ˆæ¯æ ¼å¼é€‚é…ä¸åŒæ¨¡å‹"""
    converted = []
    for msg in messages:
        if use_vlm:
            if isinstance(msg["content"], list):
                content = [{
                    "type": item["type"],
                    "image_url": {"url": item["image_url"]["url"]} if item["type"] == "image_url" else None,
                    "text": item.get("text", "")} for item in msg["content"]
                ]
            else:
                content = [{"type": "text", "text": str(msg["content"])}]
        else:
            if isinstance(msg["content"], list):
                ref_text = ""
                content = ""
                for item in msg["content"]:
                    if item.get("type") == "reference":
                        ref_text = "\n\nã€ç›¸å…³å‚è€ƒèµ„æ–™ã€‘\n"
                        for i,ref in enumerate(item.get("reference",[])):
                            ref_text += f"{i + 1}. {ref.get('content','')[:4096]}\n\næ¥æºï¼š{ref.get('title','æ— æ ‡é¢˜')} ({ref.get('link','æ— é“¾æ¥')})\n\n"
                if ref_text:
                    content = ref_text +"åŸè¾“å…¥ï¼š\n"
                text_parts = [item["text"] for item in msg["content"] if item.get("type") == "text"]
                content += " ".join(text_parts)
            else:
                content = msg["content"]
        converted.append({"role": msg["role"], "content": content})
    return converted

def refresh_convo_list():
    st.session_state.convo_list = [
        f for f in os.listdir(HISTORY_DIR)
        if f.endswith('.json') and os.path.getsize(os.path.join(HISTORY_DIR, f)) > 0
    ]
    st.session_state.convo_list.reverse()


def new_conversation():
    st.session_state.messages = []
    st.session_state.current_convo = None


def load_conversation(filename):
    path = os.path.join(HISTORY_DIR, filename)
    with open(path, 'r', encoding='utf-8') as f:
        st.session_state.messages = json.load(f)
    st.session_state.current_convo = filename

def save_conversation():
    if st.session_state.current_convo and st.session_state.messages:
        path = os.path.join(HISTORY_DIR, st.session_state.current_convo)
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(st.session_state.messages, f, ensure_ascii=False, indent=2)

# åˆå§‹åŒ–ä¼šè¯
init_session()

# ä¾§è¾¹æ å¸ƒå±€
with st.sidebar:
    st.title("å¯¹è¯ç®¡ç†")

    # æ–°å¢æ¨¡å‹è®¾ç½®åŒºåŸŸ
    st.subheader("æ¨¡å‹è®¾ç½®")

    st.session_state.enable_web_search = st.checkbox(
        "å¯ç”¨ç½‘ç»œæœç´¢ (web_search)",
        value=st.session_state.get("enable_web_search", False),
        help="å¯ç”¨ç½‘ç»œæœç´¢å¢å¼ºå›ç­”å‡†ç¡®æ€§"
    )

    st.session_state.selected_model = st.selectbox(
        "é€‰æ‹©å¯¹è¯æ¨¡å‹",
        ["deepseek-ai/DeepSeek-R1",
         "deepseek-ai/DeepSeek-V3",
         "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
         "Qwen/QwQ-32B",
         "Pro/deepseek-ai/DeepSeek-R1",
         "Pro/deepseek-ai/DeepSeek-V3"],
        index=0
    )

    # å‚æ•°è°ƒèŠ‚éƒ¨åˆ†
    col1, col2 = st.columns([3, 1])
    with col1:
        st.session_state.max_tokens = st.slider(
            "æœ€å¤§ç”Ÿæˆé•¿åº¦ (max_tokens)",
            1024, 16384, 8192,
            help="æ§åˆ¶ç”Ÿæˆå†…å®¹çš„æœ€å¤§é•¿åº¦"
        )
    with col2:
        st.session_state.max_tokens = st.number_input(
            "è¾“å…¥å€¼",
            min_value=1024,
            max_value=16384,
            value=8192,
            step=128,
            key="max_tokens_input"
        )

    col1, col2 = st.columns([3, 1])
    with col1:
        st.session_state.temperature = st.slider(
            "åˆ›é€ æ€§ (temperature)",
            0.0, 2.0, 0.6, 0.1,
            help="å€¼è¶Šå¤§ç”Ÿæˆå†…å®¹è¶Šéšæœº"
        )
    with col2:
        st.session_state.temperature = st.number_input(
            "è¾“å…¥å€¼",
            min_value=0.0,
            max_value=2.0,
            value=0.6,
            step=0.1,
            key="temp_input",
            format="%.1f"
        )

    col1, col2 = st.columns([3, 1])
    with col1:
        st.session_state.top_p = st.slider(
            "æ ¸å¿ƒé‡‡æ · (top_p)",
            0.0, 1.0, 0.95, 0.01,
            help="æ§åˆ¶ç”Ÿæˆå†…å®¹çš„å¤šæ ·æ€§"
        )
    with col2:
        st.session_state.top_p = st.number_input(
            "è¾“å…¥å€¼",
            min_value=0.0,
            max_value=1.0,
            value=0.95,
            step=0.01,
            key="top_p_input",
            format="%.2f"
        )

    if st.button("â• æ–°å»ºå¯¹è¯", use_container_width=True):
        st.session_state.messages = []
        st.session_state.current_convo = None
        st.rerun()

    st.subheader("å†å²å¯¹è¯")
    refresh_convo_list()
    for convo in st.session_state.convo_list:
        cols = st.columns([3, 1])
        with cols[0]:
            if st.button(convo[:-5], key=f"btn_{convo}", use_container_width=True):
                load_conversation(convo)
                st.rerun()
        with cols[1]:
            if st.button("Ã—", key=f"del_{convo}", type='primary'):
                os.remove(os.path.join(HISTORY_DIR, convo))
                if st.session_state.current_convo == convo:
                    new_conversation()
                st.rerun()

# ä¸»ç•Œé¢å¸ƒå±€
st.title("æ™ºèƒ½å¯¹è¯åŠ©æ‰‹ï¼ˆæ”¯æŒå›¾æ–‡ï¼‰")

# æ˜¾ç¤ºèŠå¤©è®°å½•ï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰
for msg in st.session_state.messages:
    avatar = "ğŸ§‘" if msg["role"] == "user" else "ğŸ¤–"
    with st.chat_message(msg["role"], avatar=avatar):
        # å…ˆæ˜¾ç¤ºæ¨ç†å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
        if msg["role"] == "assistant" and msg.get("reasoning"):
            with st.expander("ğŸ§  æ¨ç†è¿‡ç¨‹ï¼ˆç‚¹å‡»å±•å¼€ï¼‰"):
                st.markdown(msg["reasoning"])

        # å†æ˜¾ç¤ºæ¶ˆæ¯å†…å®¹
        if isinstance(msg["content"], list):
            for item in msg["content"]:
                if item["type"] == "image_url":
                    try:
                        base64_str = item["image_url"]["url"].split(",")[1]
                        st.image(base64.b64decode(base64_str), use_column_width=True)
                    except:
                        st.error("å›¾ç‰‡åŠ è½½å¤±è´¥")
                elif item["type"] == "text" and item["text"].strip():
                    st.markdown(item["text"])
                elif item["type"] == "reference":
                    with st.expander("ğŸ“š å‚è€ƒæ¥æºï¼ˆç‚¹å‡»å±•å¼€ï¼‰"):
                        for i, ref in enumerate(item["reference"]):
                            st.caption(f"å‚è€ƒèµ„æ–™ {i + 1}")
                            st.markdown(f"```\n{ref['content']}\n```")
                            if 'title' and 'link' in ref:
                                st.caption(f"{ref['title']}\n{ref['link']}")
        else:
            st.markdown(msg["content"])

# å¤„ç†ç”¨æˆ·è¾“å…¥ï¼ˆæ–°å¢å›¾ç‰‡ä¸Šä¼ ï¼‰
uploaded_files = st.file_uploader(
    "ğŸ“¤ ä¸Šä¼ å›¾ç‰‡ï¼ˆæ”¯æŒå¤šé€‰ï¼‰",
    type=["png", "jpg", "jpeg"],
    accept_multiple_files=True,
    key="file_uploader"
)

if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–æè¿°..."):
    # æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯å†…å®¹
    message_content = []

    # å¤„ç†ä¸Šä¼ çš„å›¾ç‰‡
    for uploaded_file in uploaded_files:
        if uploaded_file:
            base64_str = base64.b64encode(uploaded_file.read()).decode("utf-8")
            mime_type = uploaded_file.type
            message_content.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:{mime_type};base64,{base64_str}"
                }
            })
            uploaded_file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ

    # å¤„ç†æ–‡æœ¬è¾“å…¥
    if prompt.strip():
        message_content.append({
            "type": "text",
            "text": prompt.strip()
        })

    references = []

    # WEB_SEARCH æœç´¢
    if st.session_state.enable_web_search and not len(message_content) > 1:
        print("æ­£åœ¨è¿›è¡Œç½‘ç»œæœç´¢...")
        try:
            key_words = generate_search_keyword(prompt.strip())
            references = search_results(key_words)
            message_content.append({
                "type": "reference",
                "reference": references
            })
        except Exception as e:
            st.error(f"æœç´¢å¤±è´¥: {str(e)}")

    # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
    user_message = {
        "role": "user",
        "content": message_content if len(message_content) > 1 else prompt
    }
    st.session_state.messages.append(user_message)

    # ç”Ÿæˆæ–‡ä»¶åï¼ˆä¼˜å…ˆä½¿ç”¨æ–‡æœ¬å†…å®¹ï¼‰
    filename_content = prompt.strip()
    if not st.session_state.current_convo:
        print("æ­£åœ¨ç”Ÿæˆå¯¹è¯æ–‡ä»¶å...")
        st.session_state.current_convo = generate_filename(filename_content)

    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user", avatar="ğŸ§‘"):
        for item in message_content:
            if item["type"] == "image_url":
                try:
                    base64_str = item["image_url"]["url"].split(",")[1]
                    st.image(base64.b64decode(base64_str), use_column_width=True)
                except:
                    st.error("å›¾ç‰‡æ˜¾ç¤ºå¤±è´¥")
            elif item["type"] == "text":
                st.markdown(item["text"])
            elif item["type"] == "reference":
                with st.expander("ğŸ“š å‚è€ƒæ¥æºï¼ˆç‚¹å‡»å±•å¼€ï¼‰"):
                    for i, ref in enumerate(item["reference"]):
                        st.caption(f"å‚è€ƒèµ„æ–™ {i + 1}")
                        st.markdown(f"```\n{ref['content']}\n```")
                        if 'title' and 'link' in ref:
                            st.caption(f"{ref['title']}\n{ref['link']}")


    # è‡ªåŠ¨é€‰æ‹©æ¨¡å‹
    use_vlm = any(
        isinstance(msg.get("content"), list) and
        any(item.get("type") == "image_url" for item in msg.get("content", []))
        for msg in st.session_state.messages[-1:]
    )

    # å‡†å¤‡APIè¯·æ±‚
    try:
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            reasoning_placeholder = st.empty()
            answer_placeholder = st.empty()
            full_reasoning = ""
            full_answer = ""

            # è½¬æ¢æ¶ˆæ¯æ ¼å¼
            api_messages = convert_messages_for_api(st.session_state.messages, use_vlm)

            # åˆ›å»ºAPIè¯·æ±‚
            print("æ­£åœ¨å‘é€apiè¯·æ±‚...")
            stream = client.chat.completions.create(
                model=vlm_model if use_vlm else st.session_state.selected_model,
                messages=api_messages,
                stream=True,
                max_tokens=vlm_max_tokens if use_vlm else st.session_state.max_tokens,
                temperature=st.session_state.temperature,
                top_p=st.session_state.top_p
#                top_k=st.session_state.top_k
            )

            # å¤„ç†æµå¼å“åº”
            for chunk in stream:
                # å¤„ç†å¸¸è§„å›ç­”
                if chunk.choices[0].delta.content:
                    full_answer += chunk.choices[0].delta.content or ""
                    answer_placeholder.markdown(full_answer + "â–Œ")

                # å¤„ç†æ¨ç†è¿‡ç¨‹
                if hasattr(chunk.choices[0].delta, 'reasoning_content'):
                    reasoning = chunk.choices[0].delta.reasoning_content or ""
                    full_reasoning += reasoning
                    with reasoning_placeholder.expander("ğŸ¤” å®æ—¶æ¨ç†"):
                        st.markdown(full_reasoning)
            print("å“åº”æ¥å—å®Œæˆã€‚\n\n")

            # ä¿å­˜æœ€ç»ˆå“åº”
            with reasoning_placeholder:
                if full_reasoning.strip():
                    with st.expander("ğŸ§  æ¨ç†è¿‡ç¨‹"):
                        st.markdown(full_reasoning.strip())
            answer_placeholder.markdown(full_answer)
            st.session_state.messages.append({
                "role": "assistant",
                "content": full_answer,
                "reasoning": full_reasoning.strip()
            })

    except Exception as e:
        st.error(f"è¯·æ±‚å¤±è´¥: {str(e)}")
        st.session_state.messages.append({
            "role": "assistant",
            "content": "å“åº”ç”Ÿæˆå¤±è´¥",
            "reasoning": f"é”™è¯¯ä¿¡æ¯: {str(e)}"
        })

    # ä¿å­˜å¯¹è¯è®°å½•
    if st.session_state.current_convo:
        save_conversation()
        refresh_convo_list()

# è‡ªåŠ¨æ»šåŠ¨å’Œä¿å­˜åŠŸèƒ½ï¼ˆä¿æŒä¸å˜ï¼‰
st.markdown("""
<script>
window.addEventListener('DOMContentLoaded', () => {
    const scrollToBottom = () => {
        window.scrollTo(0, document.body.scrollHeight);
    };
    scrollToBottom();
});
</script>
""", unsafe_allow_html=True)